version: '3.8'

services:
  inference:
    build: .
    volumes:
      - ./engine:/app/engine
      - ./output:/app/output  # Maps local 'output' folder to container
    ports:
      - "${INFERENCE_PORT}:1337"
    command:
      - "--model-file"
      - "/app/engine/${MODEL_NAME}.eim"
      - "--run-http-server"
      - "1337"

  app:
    build: app
    depends_on:
      - inference
    volumes:
      - ./output:/app/output  # Ensure this mapping exists
